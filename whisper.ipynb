{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856cd4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Lee\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\openslr--librispeech_asr\\2712a8f82f0d20807a56faadcd08734f9bdd24c850bb118ba21ff33ebff0432f (last modified on Thu Mar 27 15:43:55 2025) since it couldn't be found locally at openslr/librispeech_asr, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f8ea909b5540e9a7cab142540d1c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e55cf7eb4c3408e9908fa55f5a25272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': 'C:\\\\Users\\\\Lee\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\9de4d8114eadf757c2efb252d3b54ad35981e4ee7ab61c3c6dd6192c7d04ba18\\\\1487-133273-0000.flac', 'array': array([ 9.15527344e-05,  4.57763672e-04,  5.18798828e-04, ...,\n",
      "       -4.57763672e-04, -5.49316406e-04, -4.88281250e-04], shape=(225920,)), 'sampling_rate': 16000}, 'text': 'THE SECOND IN IMPORTANCE IS AS FOLLOWS SOVEREIGNTY MAY BE DEFINED TO BE THE RIGHT OF MAKING LAWS IN FRANCE THE KING REALLY EXERCISES A PORTION OF THE SOVEREIGN POWER SINCE THE LAWS HAVE NO WEIGHT'}\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_from_disk\n",
    "\n",
    "# common_voice = load_from_disk(\"data/common_voice\")\n",
    "# print(common_voice)\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"openslr/librispeech_asr\")\n",
    "\n",
    "dataset = dataset.remove_columns([\"file\", \"speaker_id\", \"chapter_id\", \"id\"])\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "del dataset[\"train.clean.100\"]\n",
    "del dataset[\"train.other.500\"]\n",
    "del dataset[\"test.other\"]\n",
    "del dataset[\"validation.other\"]\n",
    "\n",
    "print(dataset[\"train.clean.360\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f300c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\",\n",
    "    token=\"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\")\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\",\n",
    "    token=\"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\")\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\",\n",
    "    token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01da545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names[\"train.clean.360\"], num_proc=1)\n",
    "\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "\n",
    "# from whisper_data_load import prep_data\n",
    "\n",
    "\n",
    "# dataset = prep_data(dataset, feature_extractor, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f626d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "from MagnetWhisper import MagnetWhisper\n",
    "\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\",token=\"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\")\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"data/models/whisper/base\")\n",
    " \n",
    " \n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "model.__class__ = MagnetWhisper \n",
    "model.load_magnet([(1, .67)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c92968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27c4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff00792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Temp\\ipykernel_15952\\343335097.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"whisper-magnet\"\n",
    "\n",
    "MODEL_NAME = \"t2-.67-long\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"./data/models/whisper/{MODEL_NAME}\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    # gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    max_steps=16000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True, \n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    # save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=\"wandb\",\n",
    "    greater_is_better=False,\n",
    "    weight_decay=.005,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train.clean.360\"],\n",
    "    eval_dataset=dataset[\"validation.clean\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133f23e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavislee4891\u001b[0m (\u001b[33mdavislee4891-ohio-state-buckeyes\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lee\\coding\\python\\AI\\Wave2Vec2ASR\\wandb\\run-20250512_090304-v6qc588m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet/runs/v6qc588m' target=\"_blank\">./data/models/whisper/t2-.67-long</a></strong> to <a href='https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet' target=\"_blank\">https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet/runs/v6qc588m' target=\"_blank\">https://wandb.ai/davislee4891-ohio-state-buckeyes/whisper-magnet/runs/v6qc588m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16000' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16000/16000 4:33:51, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.091357</td>\n",
       "      <td>4.646888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.093406</td>\n",
       "      <td>4.812323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>4.678137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.088108</td>\n",
       "      <td>4.569685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.085567</td>\n",
       "      <td>4.477777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.081202</td>\n",
       "      <td>4.308665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>4.084409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>4.067865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.079629</td>\n",
       "      <td>3.970442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.077808</td>\n",
       "      <td>3.972280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.076207</td>\n",
       "      <td>3.975957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.076602</td>\n",
       "      <td>3.865667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.075480</td>\n",
       "      <td>3.845447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.076764</td>\n",
       "      <td>3.797654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.077056</td>\n",
       "      <td>3.738833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>3.827065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import TrainerCallback\n",
    "\n",
    "# class EvaluateFirstStepCallback(TrainerCallback):\n",
    "#     def on_step_begin(self, args, state, control, **kwargs):\n",
    "#         if state.global_step == 1:\n",
    "#             control.should_evaluate = True\n",
    "\n",
    "# trainer.add_callback(EvaluateFirstStepCallback())\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(f\"./data/models/whisper/{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcb3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function map_to_pred at 0x000001CA16B15580> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0f6a7e5a3d44bcab4e58faca67c650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Temp\\ipykernel_15952\\4144303614.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_features = torch.tensor(batch[\"input_features\"]).unsqueeze(0).to(\"cuda\")  # Add batch dimension if missing\n",
      "c:\\Users\\Lee\\coding\\python\\AI\\Wave2Vec2ASR\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:503: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6698419650352205\n"
     ]
    }
   ],
   "source": [
    "def map_to_pred(batch):\n",
    "    input_features = torch.tensor(batch[\"input_features\"]).unsqueeze(0).to(\"cuda\")  # Add batch dimension if missing\n",
    "\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(processor.decode(batch['labels']))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch\n",
    "\n",
    "result = dataset[\"validation.clean\"].map(map_to_pred)\n",
    "\n",
    "wer = load(\"wer\")\n",
    "print(100 * wer.compute(references=result[\"reference\"], predictions=result[\"prediction\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
